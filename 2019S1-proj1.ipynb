{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The University of Melbourne, School of Computing and Information Systems\n",
    "# COMP30027 Machine Learning, 2019 Semester 1\n",
    "-----\n",
    "## Project 1: Gaining Information about Naive Bayes\n",
    "-----\n",
    "###### Student Name(s):\n",
    "###### Python version:\n",
    "###### Submission deadline: 1pm, Fri 5 Apr 2019"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This iPython notebook is a template which you may use for your Project 1 submission. (You are not required to use it; in particular, there is no need to use iPython if you do not like it.)\n",
    "\n",
    "Marking will be applied on the five functions that are defined in this notebook, and to your responses to the questions at the end of this notebook.\n",
    "\n",
    "You may change the prototypes of these functions, and you may write other functions, according to your requirements. We would appreciate it if the required functions were prominent/easy to find. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function opens a csv file, and transform it into a usable format \n",
    "def preprocess(filename, header):\n",
    "    dataset = []\n",
    "    with open(filename) as csvfile:\n",
    "        reader = csv.DictReader(csvfile, header)\n",
    "        for row in reader:\n",
    "            dataset.append(row)\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function builds a supervised NB model\n",
    "def train(dataset, header, classlabels, k):\n",
    "    model = []\n",
    "    classes = {}\n",
    "    count = 0\n",
    "    #First it counts the number of times different classes appear\n",
    "    for index in range(len(dataset)):\n",
    "        count += 1;\n",
    "        if dataset[index]['class'] in classes:\n",
    "            classes[dataset[index]['class']] += 1\n",
    "        else:\n",
    "            classes[dataset[index]['class']] = 1\n",
    "    classes['count'] = count\n",
    "    model.append(classes)\n",
    "    #Then it applies a smoothing technique to the rest of the data\n",
    "    #Laplace smoothing if k = 1\n",
    "    #Add-K if k < 1\n",
    "    smoothed_attribute = smoothing(header, dataset,k) \n",
    "    i = 0\n",
    "    #Then count the rest of the attributes\n",
    "    while i < len(classlabels):\n",
    "        current_class = classlabels[i]\n",
    "        j = 0\n",
    "        class_attributes = []\n",
    "        while j < len(header)-1:\n",
    "            attributes = smoothed_attribute[j].copy()\n",
    "            for index in range(len(dataset)):\n",
    "                if dataset[index]['class'] == current_class:\n",
    "                    attributes['count'] += 1\n",
    "                    attributes[dataset[index].get(header[j])] += 1\n",
    "            class_attributes.append(attributes)\n",
    "            j+=1\n",
    "        model.append(class_attributes)\n",
    "        i+=1\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def smoothing(header, dataset, k):\n",
    "    #smoothing is applied to the data in order to not an attribute with a count of 0  \n",
    "    j = 0\n",
    "    smoothed_attributes = []\n",
    "    while j < len(header)-1:\n",
    "        attribute = {}\n",
    "        count = 0\n",
    "        for index in range(len(dataset)):\n",
    "            if dataset[index][header[j]] not in attribute:\n",
    "                count += 1\n",
    "                attribute[dataset[index][header[j]]] = k\n",
    "        j+=1\n",
    "        attribute['count'] = count\n",
    "        smoothed_attributes.append(attribute)\n",
    "    return smoothed_attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function predicts the class for an instance or a set of instances, based on a trained model \n",
    "def predict(model, dataset, classlabels, header):\n",
    "    predicted_classes = []\n",
    "    highest_probability = 0\n",
    "    probability = 0\n",
    "    for index in range(len(dataset)):\n",
    "        row = dataset[index]\n",
    "        highest_probability = 0\n",
    "        probability = 0\n",
    "        predicted_label = ''\n",
    "        # Predict the class label\n",
    "        for label in classlabels:\n",
    "            # find the highest probability of a class label for an instance \n",
    "            try:\n",
    "                probability = model[0][label]/model[0]['count']\n",
    "                for attribute in range(len(row)-1):\n",
    "                    probability *= model[classlabels.index(label)+1][attribute][row.get(header[attribute])]/model[classlabels.index(label)+1][attribute]['count']\n",
    "                if probability > highest_probability:\n",
    "                    highest_probability = probability\n",
    "                    predicted_label = label\n",
    "            # if the attribute is not found than the probability = 0\n",
    "            except KeyError:\n",
    "                continue\n",
    "        predicted_classes.append(predicted_label)\n",
    "    return predicted_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function evaluates a set of predictions, in a supervised context \n",
    "def evaluate(predicted_classes, dataset):\n",
    "    correct = 0\n",
    "    wrong = 0\n",
    "    count = 0\n",
    "    # Only checks how accarate the model was\n",
    "    for index in range(len(dataset)):\n",
    "        row = dataset[index]\n",
    "        if predicted_classes[index] == row['class']:\n",
    "            correct += 1\n",
    "        else:\n",
    "            wrong += 1\n",
    "        count += 1\n",
    "    print(\"Accuracy is\", correct/count*100,\"% with\", correct,\"correct predictions and\", wrong, \"wrong predictions\" )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def class_mean_info(model, classlabels):\n",
    "    classes = model[0]\n",
    "    entropy_classes = 0\n",
    "    i = 0\n",
    "    # finds the mean info for the class labels\n",
    "    while i < len(classes)-1:\n",
    "        entropy_classes += classes[classlabels[i]]/classes['count']*math.log(classes[classlabels[i]]/classes['count'],2)\n",
    "        i += 1\n",
    "    entropy_classes = entropy_classes*(-1)\n",
    "    return entropy_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def att_mean_info(dataset, attribute):\n",
    "    attributes = {}\n",
    "    count = 0\n",
    "    for index in range(len(dataset)):\n",
    "        count += 1;\n",
    "        if dataset[index][attribute] in attributes:\n",
    "            attributes[dataset[index][attribute]] += 1\n",
    "        else:\n",
    "            attributes[dataset[index][attribute]] = 1\n",
    "    attributes['count'] = count\n",
    "    entropy_attributes = 0\n",
    "    i = 0\n",
    "    # finds the mean info for the attribute\n",
    "    for value in attributes.keys():\n",
    "        if value != 'count':\n",
    "            entropy_attributes += attributes[value]/attributes['count']*math.log(attributes[value]/attributes['count'],2)\n",
    "    entropy_attributes = entropy_attributes*(-1)\n",
    "    return entropy_attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def attributes_info(dataset, header, model, classlabels):\n",
    "    j = 0\n",
    "    attributes_values = []\n",
    "    while j < len(header)-1:\n",
    "        count = 0\n",
    "        attributes = []\n",
    "        for index in range(len(dataset)):\n",
    "            if dataset[index][header[j]] not in attributes:\n",
    "                attributes.append(dataset[index][header[j]])\n",
    "        j+=1  \n",
    "        attributes_values.append(attributes)\n",
    "    attribute_index = 0\n",
    "    entropy_attributes = []\n",
    "    for attribute_index in  range(len(header)-1):\n",
    "        mean_info = 0\n",
    "        for value in attributes_values[attribute_index]:\n",
    "            i = 1\n",
    "            j = 1\n",
    "            total = 0\n",
    "            entropy = 0\n",
    "            # find the total count of an attribute\n",
    "            while i <= len(classlabels):\n",
    "                total += model[i][attribute_index][value]-1\n",
    "                i += 1\n",
    "            # find the entropy of an attribute\n",
    "            while j <= len(classlabels):\n",
    "                if (model[j][attribute_index][value]-1)!= 0:\n",
    "                    entropy += (model[j][attribute_index][value]-1)/total*math.log((model[j][attribute_index][value]-1)/total,2)\n",
    "                j += 1\n",
    "            entropy_attribute = entropy*(-1)\n",
    "            mean_info += (total/model[0]['count'])*entropy_attribute\n",
    "        entropy_attributes.append(mean_info)\n",
    "    return entropy_attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function calculates the Information Gain of an attribute or a set of attribute, with respect to the class\n",
    "def info_gain(attributes_info,class_info, header):\n",
    "    info_gain = []\n",
    "    i = 0\n",
    "    for value in attributes_info:\n",
    "        info_gain.append(class_info-value)\n",
    "    while i < len(header)-1:\n",
    "        print(\"information gain for\", header[i], \"is\", info_gain[i])\n",
    "        i += 1\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function splits the data into trainning and testing set\n",
    "def holdout(train_percentage, test_percentage, dataset):\n",
    "    random.shuffle(dataset)\n",
    "    trainningdata = train_percentage*len(dataset)\n",
    "    testingdata = test_percentage*len(dataset) + trainningdata\n",
    "    train = dataset[:int(trainningdata)]\n",
    "    test = dataset[int(trainningdata):int(testingdata)]\n",
    "    return [train,test]\n",
    "            \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy is 90.30092592592592 % with 11703 correct predictions and 1257 wrong predictions\n",
      "information gain for parents is 0.07293460750309921\n",
      "information gain for has_nurs is 0.1964492804881155\n",
      "information gain for form is 0.005572591715219621\n",
      "information gain for children is 0.011886431475775616\n",
      "information gain for housing is 0.01960202502287145\n",
      "information gain for finance is 0.0043331270252000564\n",
      "information gain for social is 0.022232616894017898\n",
      "information gain for health is 0.958774960469976\n",
      "parents\n",
      "information gain for parents is -0.05859879195953788\n",
      "information gain for has_nurs is 0.0649158810254784\n",
      "information gain for form is -0.12596080774741747\n",
      "information gain for children is -0.11964696798686147\n",
      "information gain for housing is -0.11193137443976564\n",
      "information gain for finance is -0.12720027243743703\n",
      "information gain for social is -0.10930078256861919\n",
      "information gain for health is 0.8272415610073389\n",
      "has_nurs\n",
      "information gain for parents is 0.6783668022066682\n",
      "information gain for has_nurs is 0.8018814751916845\n",
      "information gain for form is 0.6110047864187886\n",
      "information gain for children is 0.6173186261793446\n",
      "information gain for housing is 0.6250342197264405\n",
      "information gain for finance is 0.6097653217287691\n",
      "information gain for social is 0.6276648115975869\n",
      "information gain for health is 1.564207155173545\n",
      "form\n",
      "information gain for parents is 0.35643870731930605\n",
      "information gain for has_nurs is 0.47995338030432233\n",
      "information gain for form is 0.28907669153142646\n",
      "information gain for children is 0.29539053129198245\n",
      "information gain for housing is 0.3031061248390783\n",
      "information gain for finance is 0.2878372268414069\n",
      "information gain for social is 0.30573671671022473\n",
      "information gain for health is 1.2422790602861828\n",
      "children\n",
      "information gain for parents is 0.35643870731930605\n",
      "information gain for has_nurs is 0.47995338030432233\n",
      "information gain for form is 0.28907669153142646\n",
      "information gain for children is 0.29539053129198245\n",
      "information gain for housing is 0.3031061248390783\n",
      "information gain for finance is 0.2878372268414069\n",
      "information gain for social is 0.30573671671022473\n",
      "information gain for health is 1.2422790602861828\n",
      "housing\n",
      "information gain for parents is -0.05859879195953788\n",
      "information gain for has_nurs is 0.0649158810254784\n",
      "information gain for form is -0.12596080774741747\n",
      "information gain for children is -0.11964696798686147\n",
      "information gain for housing is -0.11193137443976564\n",
      "information gain for finance is -0.12720027243743703\n",
      "information gain for social is -0.10930078256861919\n",
      "information gain for health is 0.8272415610073389\n",
      "finance\n",
      "information gain for parents is -0.643561292680694\n",
      "information gain for has_nurs is -0.5200466196956777\n",
      "information gain for form is -0.7109233084685735\n",
      "information gain for children is -0.7046094687080176\n",
      "information gain for housing is -0.6968938751609217\n",
      "information gain for finance is -0.7121627731585931\n",
      "information gain for social is -0.6942632832897753\n",
      "information gain for health is 0.24227906028618285\n",
      "social\n",
      "information gain for parents is -0.05859879195953788\n",
      "information gain for has_nurs is 0.0649158810254784\n",
      "information gain for form is -0.12596080774741747\n",
      "information gain for children is -0.11964696798686147\n",
      "information gain for housing is -0.11193137443976564\n",
      "information gain for finance is -0.12720027243743703\n",
      "information gain for social is -0.10930078256861919\n",
      "information gain for health is 0.8272415610073389\n",
      "health\n",
      "information gain for parents is -0.05859879195953788\n",
      "information gain for has_nurs is 0.0649158810254784\n",
      "information gain for form is -0.12596080774741747\n",
      "information gain for children is -0.11964696798686147\n",
      "information gain for housing is -0.11193137443976564\n",
      "information gain for finance is -0.12720027243743703\n",
      "information gain for social is -0.10930078256861919\n",
      "information gain for health is 0.8272415610073389\n",
      "Accuracy is 91.12654320987654 % with 2362 correct predictions and 230 wrong predictions\n",
      "Accuracy is 90.2854938271605 % with 11701 correct predictions and 1259 wrong predictions\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "import math\n",
    "import random\n",
    "\n",
    "#This changes depending on the file  \n",
    "filename = 'nursery.csv'\n",
    "attributes = ['parents','has_nurs','form','children','housing','finance','social','health']\n",
    "header = 'parents','has_nurs','form','children','housing','finance','social','health','class'\n",
    "classlabels = 'not_recom', 'recommend', 'very_recom', 'priority', 'spec_prior'\n",
    "\n",
    "\n",
    "#Question 1\n",
    "dataset = preprocess(filename, header)\n",
    "model = train(dataset, header, classlabels, 1)\n",
    "predicted_classes = predict(model,dataset,classlabels, header)\n",
    "evaluate(predicted_classes, dataset)\n",
    "class_info1 = class_mean_info(model, classlabels)\n",
    "attributes_info1 = attributes_info(dataset, header, model, classlabels)\n",
    "info_gain(attributes_info1,class_info1, header) \n",
    "\n",
    "#Question 2\n",
    "for attribute in attributes:\n",
    "    print(attribute)\n",
    "    entropy_attribute = att_mean_info(dataset, attribute)\n",
    "    info_gain(attributes_info1,entropy_attribute, header)\n",
    "\n",
    "#Question 4\n",
    "data = holdout(0.8,0.2,dataset)\n",
    "trainning_data = data[0]\n",
    "testing_data = data[1]\n",
    "model2 = train(trainning_data, header, classlabels, 0.02)\n",
    "predicted_classes2 = predict(model2,testing_data,classlabels, header)\n",
    "evaluate(predicted_classes2, testing_data)\n",
    "\n",
    "#Question 5\n",
    "model3 = train(dataset, header, classlabels, 0)\n",
    "predicted_classes3 = predict(model3,dataset,classlabels, header)\n",
    "evaluate(predicted_classes3, dataset)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Questions (you may respond in a cell or cells below):\n",
    "\n",
    "1. The Naive Bayes classifiers can be seen to vary, in terms of their effectiveness on the given datasets (e.g. in terms of Accuracy). Consider the Information Gain of each attribute, relative to the class distribution — does this help to explain the classifiers’ behaviour? Identify any results that are particularly surprising, and explain why they occur.\n",
    "2. The Information Gain can be seen as a kind of correlation coefficient between a pair of attributes: when the gain is low, the attribute values are uncorrelated; when the gain is high, the attribute values are correlated. In supervised ML, we typically calculate the Infomation Gain between a single attribute and the class, but it can be calculated for any pair of attributes. Using the pair-wise IG as a proxy for attribute interdependence, in which cases are our NB assumptions violated? Describe any evidence (or indeed, lack of evidence) that this is has some effect on the effectiveness of the NB classifier.\n",
    "3. Since we have gone to all of the effort of calculating Infomation Gain, we might as well use that as a criterion for building a “Decision Stump” (1-R classifier). How does the effectiveness of this classifier compare to Naive Bayes? Identify one or more cases where the effectiveness is notably different, and explain why.\n",
    "4. Evaluating the model on the same data that we use to train the model is considered to be a major mistake in Machine Learning. Implement a hold–out or cross–validation evaluation strategy. How does your estimate of effectiveness change, compared to testing on the training data? Explain why. (The result might surprise you!)\n",
    "5. Implement one of the advanced smoothing regimes (add-k, Good-Turing). Does changing the smoothing regime (or indeed, not smoothing at all) affect the effectiveness of the Naive Bayes classifier? Explain why, or why not.\n",
    "6. Naive Bayes is said to elegantly handle missing attribute values. For the datasets with missing values, is there any evidence that the performance is different on the instances with missing values, compared to the instances where all of the values are present? Does it matter which, or how many values are missing? Would a imputation strategy have any effect on this?\n",
    "\n",
    "Don't forget that groups of 1 student should respond to question (1), and one other question of your choosing. Groups of 2 students should respond to question (1) and question (2), and two other questions of your choosing. Your responses should be about 150-250 words each."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Examples:\n",
    "\n",
    "\"cmc\" Accuracy is 50.577053632043445 % with 745 correct predictions and 728 wrong predictions\n",
    "\n",
    "information gain for w-education is 0.07090633894894594\n",
    "information gain for h-education is 0.04013859922938412\n",
    "information gain for n-child is 0.10173991727554088\n",
    "information gain for w-relation is 0.009820501434385065\n",
    "information gain for w-work is 0.002582332379721608\n",
    "information gain for h-occupation is 0.030474214560266777\n",
    "information gain for standard-of-living is 0.032511460053806784\n",
    "information gain for media-exposure is 0.01578645559562042\n",
    "\n",
    "\"car\" Accuracy is 87.15277777777779 % with 1506 correct predictions and 222 wrong predictions\n",
    "\n",
    "information gain for buying is 0.09644896916961399\n",
    "information gain for maint is 0.07370394692148596\n",
    "information gain for doors is 0.004485716626632108\n",
    "information gain for persons is 0.2196629633399082\n",
    "information gain for lug_boot is 0.030008141247605424\n",
    "information gain for safety is 0.26218435655426386\n",
    "\n",
    "\"nursery\" Accuracy is 90.30092592592592 % with 11703 correct predictions and 1257 wrong predictions\n",
    "\n",
    "information gain for parents is 0.07293460750309921\n",
    "information gain for has_nurs is 0.1964492804881155\n",
    "information gain for form is 0.005572591715219621\n",
    "information gain for children is 0.011886431475775616\n",
    "information gain for housing is 0.01960202502287145\n",
    "information gain for finance is 0.0043331270252000564\n",
    "information gain for social is 0.022232616894017898\n",
    "information gain for health is 0.958774960469976\n",
    "\n",
    "\"anneal\" Accuracy is 92.20489977728286 % with 828 correct predictions and 70 wrong predictions\n",
    "\n",
    "information gain for family is 0.40908953764451006\n",
    "information gain for product-type is 0.0\n",
    "information gain for steel is 0.3060515354289405\n",
    "information gain for carbon is 0.051344088764404106\n",
    "information gain for hardness is 0.29108220585994726\n",
    "information gain for temper_rolling is 0.14711886228095605\n",
    "information gain for condition is 0.2137228803159088\n",
    "information gain for formability is 0.29223544065798446\n",
    "information gain for strength is 0.1261663361036096\n",
    "information gain for non-ageing is 0.14107379163812883\n",
    "information gain for surface-finish is 0.032488406491841815\n",
    "information gain for surface-quality is 0.43517783626288564\n",
    "information gain for enamelability is 0.03870173274881061\n",
    "information gain for bc is 0.0004376065202120749\n",
    "information gain for bf is 0.03935557414283686\n",
    "information gain for bt is 0.021775078259213876\n",
    "information gain for bw-me is 0.037997478813511565\n",
    "information gain for bl is 0.036703081364408474\n",
    "information gain for m is 0.0\n",
    "information gain for chrom is 0.11722522630372056\n",
    "information gain for phos is 0.02975374520863916\n",
    "information gain for cbond is 0.02704235332867677\n",
    "information gain for marvi is 0.0\n",
    "information gain for exptl is 0.015604780443500665\n",
    "information gain for ferro is 0.13718113252042574\n",
    "information gain for corr is 0.0\n",
    "information gain for bbvc is 0.0223970898516459\n",
    "information gain for lustre is 0.01824168402125048\n",
    "information gain for jurofm is 0.0\n",
    "information gain for s is 0.0\n",
    "information gain for p is 0.0\n",
    "information gain for shape is 0.04323960556514961\n",
    "information gain for oil is 0.03303757117705719\n",
    "information gain for bore is 0.01937886432831948\n",
    "information gain for packing is 0.003958783545891853"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1: \n",
    "    The Native Bayes accuracy does seem to be correlated to the information gain of each attribute. \n",
    "    For the cmc dataset, the accuracy was 50.58% and had a total information gain of 0.303959819. While the nursery dataset had\n",
    "    an accuracy of 90.3% and an information gain of 1.291785641. This accuracy difference is not due to the number of \n",
    "    attributes the dataset had because both datasets had the same number of attributes. Moreover, the car dataset had fewer \n",
    "    attributes than cmc but it had a higher accuracy of 87.15%. Its information gain was 0.686494094, which is greater than\n",
    "    the one for cmc. However, datasets with more attributes are more likely to be more accurate beacause the resulting\n",
    "    information gain is likely to be higher, for example, the anneal dataset has 35 attributes and has a very high accuracy of       92.2% and a information gain of 3.08758231. Thus, information gain does help to explain the classifers' behaviour. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2:\n",
    "    We assume for the Native Bayes classifier that the datasets' attributes are independent. However, there are some attributes     that break that assumption, for example, in the nursery dataset, the attribute has_nurs and health have a very high             pair-wise information gain of 1.54. Even though there are attributes that break our assumption, the overall affect on the       model appears to be very small. The accuracy of the model is at 90.3%, however, the information gain for attributes that         have a high correlation with health (has_nurs,form,children) are very low. This could be due to the fact that since they are     very positively correlated with health, the model can not gain more information from these attributes. This could affect the     accuracy of the overall model, as the lower the information gain per attribute the lower accuracy of the model will be.         However, it is unlikely that all the attributes are positive correlated with each other. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4:\n",
    "    The estimate of the model does change when using the holdout method. When the model is trained over the same data that \n",
    "    it will be evaluated with, the model is going to very accurate. Therefore, when implementing a holdout strategy, it is not\n",
    "    likely to be as accurate as a model that can see all the data. Moreover, the more data that you hide from the model, the         worst it is more likely to be. For example, the anneal dataset has an accuracy of 92.2% when the model has access to all the     data but this drops down to 91.1% when 90% of data is used as the training set. However, this is not guaranteed to happen,       it is possible that the holdout splits the data in such a way that the testing data has less outliers, which can make the       the model accurate. When the model was trained on 80% of the data, its accuracy increased to 92.78%.\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5: \n",
    "    Changing the smoothing regime does affect the accuracy of the model. With add-k smoothing the model does seem to preform         better, for example the anneal dataset model's accuracy increases from 92.2% to 93.76% when k = 0.5. However, this is           somewhat misleading as the dataset is trainned and evaluted over the same data. This means there is no reason to use             smoothing and only makes the model more inaccurate as the model takes into consideration attributes that will not appear         during the testing. Thus, with no smoothing the model becomes even more accurate, eg for anneal the model's accuracy             increases to 98.99% with k = 0. This changes when the holdout strategy is used in conjunction with add-k smoothing because       the model does need to take into consideration all possible attributes that could appear. In this case, the add-k performs       better than laplace smoothing and the lower the k, the more accurate the model becomes."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
